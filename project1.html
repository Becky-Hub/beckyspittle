<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Leveraging Proxemic Dimensions for Context Aware XR Interaction</title>
    <link rel="stylesheet" href="project-style.css">
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
</head>
<body>
    <header>
        <nav>
            <div class="nav-container">
                <div class="name">
                    <a href="/">Becky Spittle</a>
                </div>
                <ul class="nav-links" id="nav-links">
                    <li><a href="index.html#about">About</a></li>
                    <li><a href="index.html#projects">Projects</a></li>
                    <li><a href="index.html#resume">Resume</a></li>
                    <li><a href="index.html#contact">Contact</a></li>
                </ul>
            </div>
        </nav>
    </header>

    <div class="page-wrapper">
        <section id="project-detail">
            <div class="project">
                <h1>Leveraging Proxemic Dimensions for Context Aware XR Interaction</h1>

                <p>This project encompasses my PhD research, investigating how proxemic dimensions—distance, orientation, movement, identity, and location—can be leveraged to enhance interactions in XR environments. By exploring the advantages, limitations, and affordances of common interaction techniques in different situations and use cases, this research contributes to the development of more intuitive, adaptive, and contextually aware XR systems that improve user experience, interaction flow, and efficiency. This research aims to help uncover how technology can further enhance user experiences and how we can leverage XR and ML/AI to improve everyday interactions.</p>


                <h2>Project Details</h2>
                <p>The research involved three studies:</p>
                <div class="accordion">
                    <div class="accordion-item">
                        <h3 class="accordion-title">
                            Study 1: Comparing Interaction Techniques within the Intimate Proxemic Zone
                            <span class="accordion-icon">&#9662;</span> <!-- Downward arrow -->
                        </h3>
                        <div class="accordion-content">
                            <p><strong>Interaction Techniques:</strong> Hand Press, Hand Hover, Eye Gaze, and Head Gaze.</p>
                            <p><strong>Tasks:</strong> 32 participants performed a series of "observe and interact" selection tasks. A cube with a symbol on was generated to
                                indicate the target object. After 5 seconds, participants were prompted via text to "go" and the trial would begin.</p>
                            <p><strong>Data Collected:</strong> Selection time, error rate, task load, user experience and preference.</p>
                        </div>
                    </div>
                    
                    <div class="accordion-item">
                        <h3 class="accordion-title">
                            Study 2: Comparing Interaction Techniques across Personal, Social, and Public Zones
                            <span class="accordion-icon">&#9662;</span> <!-- Downward arrow -->
                        </h3>
                        <div class="accordion-content">
                            <p><strong>Interaction Techniques:</strong> Hand Airtap, Hand Hover, Eye Gaze, and Head Gaze.</p>
                            <p><strong>Tasks:</strong> 32 participants performed a series of "observe and interact" selection tasks. A cube with a symbol on was generated to
                                indicate the target object. After 5 seconds, participants were prompted via text to "go" and the trial would begin. Selection tasks presented randomly across the three proxemic zones.</p>
                            <p><strong>Data Collected:</strong> Selection time, error rate, task load, user experience and preference, with focus on how distance impacts techniques.</p>
                        </div>
                    </div>
                    
                    <div class="accordion-item">
                        <h3 class="accordion-title">
                            Study 3: Exploring User-Defined Distance and Locomotion
                            <span class="accordion-icon">&#9662;</span> <!-- Downward arrow -->
                        </h3>
                        <div class="accordion-content">
                            <p><strong>Interaction Techniques:</strong> Hand Airtap, Hand Hover, Eye Gaze, and Head Gaze.</p>
                            <p><strong>Tasks:</strong> 40 participants performed a series of "observe and interact" selection tasks. A cube with a symbol on was generated to
                                indicate the target object. After 5 seconds, participants were prompted via text to "go" and the trial would begin. Objects were presented in a room-scale environment, 6.5m away from the user.</p>
                            <p><strong>Data Collected:</strong> User-defined position, locomotion speed, selection time, task load, user experience, and preference, with focus on how object size impacts approaches with different techniques.</p>
                        </div>
                    </div>
                </div>
                
                

                <h2>Key Findings and Impact</h2>
                <div class="findings-container">
                    <div class="finding">
                        <i class="fas fa-arrow-circle-right"></i>
                        <p><b>Distance Impacts Techniques:</b> The appropriateness of interaction techniques varied significantly with distance.</p>
                    </div>
                    <div class="finding">
                        <i class="fas fa-arrow-circle-right"></i>
                        <p><b>Users Adapt their Behaviours Based on Technique:</b> Users naturally adjusted interaction approaches based on the affordances of techniques, preferring not to expend extra energy to approach objects physically.</p>
                    </div>
                    <div class="finding">
                        <i class="fas fa-arrow-circle-right"></i>
                        <p><b>Potential for Adaptive Interactions:</b> There is potential to enhance user experience and efficiency via adaptive systems, which switch techniques based on dimensions of proxemic interaction.</p>
                    </div>
                    <div class="finding">
                        <i class="fas fa-arrow-circle-right"></i>
                        <p><b>User Preferences Vary:</b> Users have distinct preferences for interaction techniques regardless of distance and context, emphasizing the value of personalised XR systems.</p>
                    </div>
                </div>
                
                <p>The research demonstrates the potential of leveraging proxemic dimensions to inform the design of more flexible and practical XR interactions, offering routes towards more impactful user experiences.</p>

                <h2>Skills Employed</h2>
                <p>Key skills needed to complete the project were:</p>
                <ul>
                    <li><b>Research: </b></li>
                    <li><b>Design:</b></li>
                    <li><b>Development:</b></li>
                    <li><b>Analysis:</b></li>
                </ul>

                <p>For more details on this work, please get in touch!</p>


                <a class="back-to-projects" href="index.html#projects">Back to Projects</a>
            </div>
        </section>
    </div>

    <footer>
        <p>&copy; 2024 Becky Spittle. All rights reserved.</p>
    </footer>

    <div class="hamburger" id="hamburger-menu">
        <i class="fas fa-bars"></i>
    </div>

    <div class="mobile-nav" id="mobile-nav">
        <a href="index.html#about"><i class="fas fa-user"></i> About</a>
        <a href="index.html#projects"><i class="fas fa-briefcase"></i> Projects</a>
        <a href="index.html#resume"><i class="fas fa-file-alt"></i> Resume</a>
        <a href="index.html#contact"><i class="fas fa-envelope"></i> Contact</a>
    </div>

    <button id="contact-me-button">Contact Me</button>

    <script src="script.js"></script>
</body>
</html>
